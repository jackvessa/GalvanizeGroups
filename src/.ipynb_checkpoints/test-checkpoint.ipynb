{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "# Imports for NLP Analysis of Columns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create Group Sizes\n",
    "def calc_group_sizes(num_students, num_groups):\n",
    "    '''\n",
    "    Parameters\n",
    "    -----------\n",
    "    num_students : int\n",
    "        Number of students in the class\n",
    "    num_groups : int\n",
    "        Number of groups to break students into\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    group_size : List of ideal group sizes\n",
    "    '''\n",
    "    group_sizes = []\n",
    "\n",
    "    class_size = int(num_students)\n",
    "    group_num_count = int(num_groups)\n",
    "    group_num = int(num_groups)\n",
    "\n",
    "    for i in range(group_num_count):\n",
    "        temp = class_size // group_num\n",
    "        class_size -= temp\n",
    "        group_num -= 1\n",
    "        group_sizes.append(temp)\n",
    "\n",
    "    return group_sizes\n",
    "\n",
    "# Clean DataFrame by Section\n",
    "def clean_file(dataframe):\n",
    "    '''\n",
    "    Clean CSV file\n",
    "    --------------------\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    .csv file :\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    Pandas DataFrame (Cleaned)\n",
    "    '''\n",
    "    df = dataframe.copy()\n",
    "    df.set_index(keys=df['FIRST'],inplace=True)\n",
    "\n",
    "    try:\n",
    "        df.drop(columns=['FIRST','LAST','GITHUB','Class Rank','Overall Average'],inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].str.rstrip('%').astype('float') / 100.0\n",
    "    \n",
    "#     df = df.select_dtypes(exclude=['object','bool'])\n",
    "\n",
    "#     df.drop(columns=['id','section_sis_id','attempt'],inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# def clean_file_galvanize(df):\n",
    "#     '''\n",
    "#     '''\n",
    "#     temp_df = df.copy()\n",
    "#     temp_df.drop(columns=['LAST', 'GITHUB','Class Rank'], inplace=True)\n",
    "\n",
    "#     temp_df.set_index('FIRST', inplace=True)\n",
    "\n",
    "#     for col in temp_df.columns:\n",
    "\n",
    "#         temp_df[col] = temp_df[col].apply(lambda x: float((str(x).replace(\"%\",\"\"))))\n",
    "\n",
    "#     return temp_df\n",
    "\n",
    "# Normalize DataFrame (0-1)\n",
    "def normalize_df(df):\n",
    "    '''\n",
    "    Normalize DataFrame Values from 0-1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame to Normalize\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Normalized DataFrame\n",
    "    '''\n",
    "    return df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)) \\\n",
    "        if np.min(x) != np.max(x) else x)\n",
    "\n",
    "# Add Cluster Column to DataFrame\n",
    "def add_clusters(df, num_clusters=6):\n",
    "    '''\n",
    "    Add Clusters\n",
    "    '''\n",
    "    kmeans = KMeans(num_clusters)\n",
    "    kmeans.fit(df)\n",
    "    cluster = kmeans.predict(df)\n",
    "    df['Cluster'] = cluster\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_clusters(assessment_df, num_clusters = 3):\n",
    "    results_array = []\n",
    "    student_dict = dict()\n",
    "    cluster_averages = dict()\n",
    "    \n",
    "    student_df = clean_file(assessment_df)\n",
    "    student_df = normalize_df(student_df)\n",
    "    student_df = add_clusters(student_df, num_clusters = num_clusters)\n",
    "    results_array.append(student_df)\n",
    "    \n",
    "    result = return_cluster_list(student_df, num_clusters = num_clusters)\n",
    "    results_array.append(result)\n",
    "    \n",
    "    for i,val in enumerate(result):\n",
    "        avg = round(np.mean(np.mean(student_df.loc[val].iloc[:,:-1]).values)*100, 2)\n",
    "        student_dict[i] = val\n",
    "        cluster_averages[i] = avg\n",
    "    \n",
    "    results_array.append(student_dict)\n",
    "    results_array.append(cluster_averages)\n",
    "\n",
    "    clusters, scores = generate_clusters_and_scores(results_array)\n",
    "    \n",
    "    return clusters, scores    \n",
    "\n",
    "\n",
    "def generate_clusters_and_scores(temp_arr):\n",
    "    \n",
    "    cluster_students_array = []\n",
    "    cluster_students_scores_array = []\n",
    "\n",
    "    for key, cluster in temp_arr[2].items():\n",
    "        cluster_students_array.append(cluster)\n",
    "        \n",
    "    for key, score in temp_arr[3].items():\n",
    "        cluster_students_scores_array.append(score)\n",
    "        \n",
    "    return cluster_students_array, cluster_students_scores_array\n",
    "\n",
    "\n",
    "# Generate Optimized Group (Based on Residual Sum of Squares)\n",
    "def generate_optimized_groups(student_df, num_iter = 100, num_groups = 6, Homogeneous = 0, criteria = 'score'):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    student_df : DataFrame with student names as index and score column\n",
    "    num_iter : int\n",
    "        Number of Iterations to run loss function\n",
    "    num_groups : int\n",
    "        Number of groups to divide students into\n",
    "    Homogeneous : bool\n",
    "        If True, create Homogeneous (similar) groups.\n",
    "        If False, create Heterogeneous (different) groups\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Optimal Groups\n",
    "    '''\n",
    "    index_list = list(student_df.index)\n",
    "\n",
    "    if Homogeneous == 0:\n",
    "        ideal_loss = 9999\n",
    "    elif Homogeneous == 1:\n",
    "        ideal_loss = 0\n",
    "    num_students = len(student_df)\n",
    "\n",
    "    size_list = calc_group_sizes(num_students,num_groups)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        randomized_index_list = np.random.choice(index_list, size = len(index_list),replace=False)\n",
    "        group_set = set({})\n",
    "        index_track = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        for num in size_list:\n",
    "            j = frozenset(randomized_index_list[0 + index_track:index_track+num])\n",
    "            group_set.add(j)\n",
    "            index_track += num\n",
    "\n",
    "        for group in group_set:\n",
    "            unfrozen = set(group)\n",
    "            group_loss = 0\n",
    "            avg_score = np.mean(student_df.loc[unfrozen][criteria])\n",
    "\n",
    "            for s in range(len(group)):\n",
    "                group_loss += (student_df.loc[unfrozen][criteria][s] - avg_score) ** 2\n",
    "\n",
    "            total_loss += group_loss\n",
    "\n",
    "        if Homogeneous == 0 and total_loss < ideal_loss:\n",
    "            ideal_loss = total_loss\n",
    "            best_group = group_set\n",
    "            print(\"New Best Homogeneous Group Loss:\", ideal_loss)\n",
    "\n",
    "        elif Homogeneous == 1 and total_loss > ideal_loss:\n",
    "            ideal_loss = total_loss\n",
    "            best_group = group_set\n",
    "            print(\"New Best Heterogeneous Group Loss:\", ideal_loss)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Final Best Group Loss:\", ideal_loss)\n",
    "    print(\"Final Best Grouping:\\n\")\n",
    "\n",
    "\n",
    "    for i,g in enumerate(best_group):\n",
    "        print(\"Group\",i+1)\n",
    "        print(student_df.loc[set(g)][criteria],\"\\n\")\n",
    "\n",
    "    return best_group\n",
    "\n",
    "\n",
    "# Make Student Strength/Growth Areas DataFrame\n",
    "def make_student_growth_and_strength_df(df_original,sectionID,cluster_labels):\n",
    "    '''\n",
    "    Create a DataFrame that includes students strengths and growth areas for question clusters\n",
    "\n",
    "    Return a List of Clustered Students\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "    sectionID : Section Number for Students\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame with strengths and growth areas for question clusters\n",
    "\n",
    "    '''\n",
    "    df = df_original.copy()\n",
    "    clean_df = clean_file(df,sectionID)\n",
    "    quest_num_df = clean_df.iloc[:,0:-3]\n",
    "    quest_num_df.columns = cluster_labels\n",
    "    quest_num_df_grouped = quest_num_df.groupby(quest_num_df.columns, axis=1).sum()\n",
    "    grouped_quest_normed_df = normalize_df(quest_num_df_grouped)\n",
    "\n",
    "    x = grouped_quest_normed_df.copy().ix[0]\n",
    "    x.index[x.argmin()]\n",
    "    min_list, max_list = [], []\n",
    "\n",
    "    for i in range (len(grouped_quest_normed_df)):\n",
    "        x = grouped_quest_normed_df.ix[i]\n",
    "\n",
    "        min_list.append(x.index[x.argmin()])\n",
    "        max_list.append(x.index[x.argmax()])\n",
    "\n",
    "\n",
    "    grouped_quest_normed_df['Strength Area'] = max_list\n",
    "    grouped_quest_normed_df['Growth Area'] = min_list\n",
    "\n",
    "    return grouped_quest_normed_df\n",
    "\n",
    "\n",
    "# Generate Growth Areas Groups\n",
    "def generate_growth_groups(df,num_groups):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    student_df : DataFrame with student names as index and Strength/Growth Areas included\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Growth Area Groups\n",
    "    '''\n",
    "    index_list = list(df.index)\n",
    "\n",
    "    cluster_focus = []\n",
    "\n",
    "    for i in range(num_groups):\n",
    "\n",
    "        cluster_focus.append(list(df[df['Growth Area']==i].index))\n",
    "\n",
    "    print(\"Grouping by Growth Areas:\\n\")\n",
    "\n",
    "    for i,g in enumerate(cluster_focus):\n",
    "        print(\"Group\",i+1)\n",
    "        print(str(g)+\"\\n\")\n",
    "\n",
    "    return cluster_focus\n",
    "\n",
    "\n",
    "# Generate Strength Areas Groups\n",
    "def generate_strength_groups(df,num_groups):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    student_df : DataFrame with student names as index and Strength/Growth Areas included\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Growth Area Groups\n",
    "    '''\n",
    "    index_list = list(df.index)\n",
    "\n",
    "    cluster_focus = []\n",
    "\n",
    "    for i in range(num_groups):\n",
    "\n",
    "        cluster_focus.append(list(df[df['Strength Area']==i].index))\n",
    "\n",
    "    print(\"Grouping by Strength Areas:\\n\")\n",
    "\n",
    "    for i,g in enumerate(cluster_focus):\n",
    "        print(\"Group\",i+1)\n",
    "        print(str(g)+\"\\n\")\n",
    "\n",
    "    return cluster_focus\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_assessment_df = pd.read_csv('../data/Student_Assessments.csv')\n",
    "clusters, scores = create_clusters(student_assessment_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ant-Man',\n",
       "  'Iron Man',\n",
       "  'Mystique',\n",
       "  'Groot',\n",
       "  'Superman',\n",
       "  'Superwoman',\n",
       "  'Mister Fantastic',\n",
       "  'Nightcrawler',\n",
       "  'Cyclops'],\n",
       " ['Storm',\n",
       "  'Deadpool',\n",
       "  'Wolverine',\n",
       "  'Thing',\n",
       "  'Doctor Doom',\n",
       "  'Elektra',\n",
       "  'Green Arrow'],\n",
       " ['Black Widow',\n",
       "  'Swamp Thing',\n",
       "  'Rocket Raccoon',\n",
       "  'Steel',\n",
       "  'Batman',\n",
       "  'Susan Storm',\n",
       "  'Catwoman',\n",
       "  'Wonder Woman']]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52.41, 81.91, 29.16]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# students_file = pd.read_csv('../data/students.csv')\n",
    "# past_pairs = pd.read_csv('../data/past_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_pairs(students_file,past_pairs_file):\n",
    "#     print(students_file)\n",
    "#     print(past_pairs_file)\n",
    "#     ! python pairs.py students_file, past_pairs_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_pairs(students_file,past_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !python pairs.py students_file, past_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
